{
  "project": "office2pdf",
  "branchName": "ralph/phase12-text-fidelity",
  "description": "Phase 12: Text Fidelity & Visual Polish - PDF text verification, Unicode normalization, border styles, multi-column layout, BiDi text",
  "userStories": [
    {
      "id": "US-100",
      "title": "Add PDF text content verification to test suite",
      "description": "Add a lightweight PDF text extraction step to selected fixture tests to verify that actual text in generated PDFs matches the source document.\n\nImplement:\n1. Add `pdf-extract` or `lopdf` as a dev-dependency for text extraction from PDFs\n2. Create a test utility function `extract_pdf_text(pdf_bytes: &[u8]) -> String` in a test helpers module\n3. Add golden text assertions to at least 5 DOCX, 3 PPTX, and 3 XLSX fixture tests\n4. Assertions should check for presence of key content markers (headings, table headers, specific words) — not exact layout\n5. Include CJK content verification if Korean/Chinese/Japanese fixtures exist\n\nThis catches regressions where text is correct in IR but missing/garbled in the final PDF due to codegen or compilation bugs.\n\nRelated: #60",
      "acceptanceCriteria": [
        "PDF text extraction utility function available in test helpers",
        "At least 5 DOCX fixture tests have text content assertions",
        "At least 3 PPTX fixture tests have text content assertions",
        "At least 3 XLSX fixture tests have text content assertions",
        "Tests verify presence of key content markers, not exact layout",
        "No false positives from font encoding differences",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 1,
      "passes": false,
      "notes": "Use lopdf (already a dependency behind pdf-ops feature) or pdf-extract as a dev-dependency. The key is spot-checking: assert that known strings from the source document appear in the extracted PDF text. This is not a full round-trip test — just content markers. Place the helper in tests/common/mod.rs or a similar shared test utility. If lopdf's text extraction is limited, consider pdf-extract crate which provides better text extraction."
    },
    {
      "id": "US-101",
      "title": "Add Unicode NFC normalization to the text pipeline",
      "description": "Normalize all text to NFC form before Typst codegen to prevent decomposed Unicode issues in generated PDFs.\n\nImplement:\n1. Use `unicode-normalization` crate (likely already a transitive dependency via Typst) to apply NFC\n2. Add normalization at the IR boundary — when text enters `Run.text` from any parser, or as a single chokepoint in `escape_typst()`\n3. Test with Korean NFD input (decomposed jamo) to verify composed output\n4. Test with combining diacritics (e.g., cafe with combining accent) to verify NFC output\n5. Ensure no regression in existing fixture tests\n\nRelated: #57",
      "acceptanceCriteria": [
        "All Run.text values are NFC-normalized before reaching Typst codegen",
        "Test with Korean NFD input produces composed hangul in output",
        "Test with combining diacritics produces NFC characters in output",
        "unicode-normalization is added as a dependency (or reused from transitive)",
        "No regression in existing fixture tests",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 2,
      "passes": false,
      "notes": "Check if unicode-normalization is already a transitive dependency via typst or typst-kit. If so, just add it as a direct dependency without version conflict. The simplest approach is to normalize in escape_typst() as a single chokepoint — all text passes through there. Alternatively normalize in each parser when constructing Run structs. Prefer the chokepoint approach for maintainability."
    },
    {
      "id": "US-102",
      "title": "Add dash patterns and line styles to border/shape rendering",
      "description": "Extend the IR and parsers to support border line styles beyond solid lines.\n\nImplement:\n1. Add `BorderStyle` enum to IR: Solid, Dashed, Dotted, DashDot, DashDotDot, Double, None\n2. Add `style: BorderStyle` field to `BorderSide` struct (default: Solid)\n3. Parse DOCX border styles from `<w:bdr w:val=\"dashed\">` etc.\n4. Parse PPTX outline dash patterns from `<a:prstDash val=\"dash\"/>`\n5. Parse XLSX cell border style types (thin, medium, dashed, dotted, etc.)\n6. Map border styles to Typst stroke patterns using `stroke(dash: \"dashed\")` or custom dash arrays\n7. Add test fixtures for dashed/dotted borders in each format\n\nRelated: #59",
      "acceptanceCriteria": [
        "BorderStyle enum covers common Office line styles (Solid, Dashed, Dotted, DashDot, DashDotDot, Double, None)",
        "BorderSide struct has a style field with default Solid",
        "DOCX paragraph/table borders parse dash pattern from w:val attribute",
        "PPTX shape outline parses prstDash element",
        "XLSX cell borders map style types (thin, medium, dashed, dotted)",
        "Typst codegen emits correct dash patterns for non-solid borders",
        "Test fixtures verify dashed/dotted borders render correctly",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 3,
      "passes": false,
      "notes": "The Typst stroke API supports dash patterns: `stroke(paint: color, thickness: 1pt, dash: \"dashed\")`. Valid dash values include: 'solid', 'dotted', 'densely-dotted', 'loosely-dotted', 'dashed', 'densely-dashed', 'loosely-dashed', 'dash-dotted', 'densely-dash-dotted', 'loosely-dash-dotted'. Map OOXML border values to the closest Typst dash pattern. For Double borders, emit two parallel strokes or use Typst's table stroke capabilities."
    },
    {
      "id": "US-103",
      "title": "Support DOCX multi-column section layout",
      "description": "Parse and render multi-column section layouts from DOCX documents.\n\nImplement:\n1. Parse `<w:cols>` from `<w:sectPr>` in the DOCX parser — extract column count, spacing, equalWidth flag, and optional per-column widths\n2. Add column layout information to IR (e.g., ColumnLayout struct with num_columns, spacing, column_widths)\n3. Emit Typst `#columns(n, gutter: ...)` for multi-column sections\n4. Handle column breaks (`<w:br w:type=\"column\"/>`) by emitting `#colbreak()`\n5. Test with 2-column and 3-column DOCX fixtures\n6. Support unequal column widths if specified\n\nRelated: #58",
      "acceptanceCriteria": [
        "Parse w:cols from sectPr with num, space, equalWidth, per-column widths",
        "IR has ColumnLayout type with column count, spacing, and optional widths",
        "Typst codegen emits columns() for multi-column sections",
        "Column breaks (w:br type=column) emit colbreak() in Typst",
        "Test with 2-column DOCX fixture renders correctly",
        "Test with 3-column DOCX fixture renders correctly",
        "Unequal column widths are respected when specified",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 4,
      "passes": false,
      "notes": "Typst columns: `#columns(2, gutter: 12pt)[content]`. For sections with different column counts, wrap each section's content in its own columns() call. The DOCX sectPr can appear at the end of a section (within the last paragraph's pPr) or as the document's final sectPr. Parse both cases. For unequal columns, Typst doesn't have direct per-column width support in columns(), so use #grid() with explicit column widths as a fallback."
    },
    {
      "id": "US-104",
      "title": "Support BiDi (right-to-left) text and complex script shaping",
      "description": "Add support for bidirectional text rendering for Arabic, Hebrew, and other RTL scripts.\n\nImplement:\n1. Add `TextDirection` enum (LTR, RTL) to IR\n2. Add `direction: Option<TextDirection>` to ParagraphStyle and TextStyle\n3. Parse DOCX `<w:bidi/>` on paragraphs and `<w:rtl/>` on runs\n4. Parse PPTX `<a:pPr rtl=\"1\"/>` and `<a:rPr lang=\"ar-SA\"/>` attributes\n5. Emit Typst `#set text(dir: rtl)` for RTL paragraphs/runs\n6. Ensure font substitution can select RTL-capable fonts (e.g., Noto Sans Arabic)\n7. Create test fixtures with Arabic/Hebrew DOCX content\n8. Test mixed LTR/RTL paragraph (Arabic with English numbers)\n\nTypst has built-in BiDi support via the Unicode Bidirectional Algorithm, so the main work is passing direction hints from the source document through to Typst.\n\nRelated: #61",
      "acceptanceCriteria": [
        "TextDirection enum (LTR, RTL) exists in IR",
        "ParagraphStyle and TextStyle have optional direction field",
        "DOCX w:bidi and w:rtl are parsed correctly",
        "PPTX rtl attribute on pPr is parsed correctly",
        "Typst codegen emits set text(dir: rtl) for RTL content",
        "Test fixture with Arabic/Hebrew content renders RTL",
        "Mixed LTR/RTL paragraph test passes (Arabic with English numbers)",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 5,
      "passes": false,
      "notes": "Typst's text direction: `#set text(dir: rtl)` or inline `#text(dir: rtl)[content]`. Typst handles the Unicode BiDi algorithm internally — we just need to signal the base direction. For mixed content, Typst auto-detects script direction within a paragraph if the base direction is set. Focus on paragraph-level direction first (w:bidi), then run-level (w:rtl) for overrides. Font substitution for Arabic/Hebrew may require adding Noto Sans Arabic to the embedded fonts or ensuring system font discovery includes RTL fonts."
    }
  ]
}
