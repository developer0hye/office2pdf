{
  "project": "office2pdf",
  "branchName": "ralph/phase11-ecosystem",
  "description": "Phase 11: Ecosystem Expansion - PDF merge/split, tagged PDF/accessibility, TypeScript types, streaming API, Prometheus metrics",
  "userStories": [
    {
      "id": "US-095",
      "title": "Add PDF merge and split capabilities",
      "description": "Inspired by Gotenberg and Stirling-PDF, add basic PDF manipulation beyond conversion.\n\nImplement merge and split:\n1. Add a `pdf` module to the library (`crates/office2pdf/src/pdf_ops.rs` or similar)\n2. **Merge**: `pdf::merge(inputs: &[&[u8]]) -> Result<Vec<u8>>` — concatenate multiple PDFs into one\n3. **Split**: `pdf::split(input: &[u8], ranges: &[PageRange]) -> Result<Vec<Vec<u8>>>` — extract page ranges\n4. **Page count**: `pdf::page_count(input: &[u8]) -> Result<u32>` — count pages in a PDF\n5. Use `lopdf` crate for PDF manipulation (lightweight, pure Rust)\n6. Add CLI subcommands:\n   - `office2pdf merge file1.pdf file2.pdf -o output.pdf`\n   - `office2pdf split input.pdf --pages 1-5,10-15 --outdir splits/`\n7. These operations work on existing PDFs — independent from the conversion pipeline\n\nThis makes office2pdf a more complete PDF toolkit, reducing the need for external tools after conversion.",
      "acceptanceCriteria": [
        "pdf::merge() concatenates multiple PDF byte arrays into one valid PDF",
        "pdf::split() extracts specified page ranges into separate PDFs",
        "pdf::page_count() returns correct page count",
        "CLI merge subcommand combines multiple PDF files",
        "CLI split subcommand extracts page ranges",
        "Unit test: merge 2 single-page PDFs produces 2-page PDF",
        "Unit test: split 4-page PDF at pages 1-2 and 3-4 produces 2 PDFs",
        "Unit test: page_count returns correct count",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 1,
      "passes": true,
      "notes": "Use lopdf (pure Rust PDF library) for manipulation. It can read, modify, and write PDFs. For merge: read each PDF, copy pages to a new document. For split: read the PDF, extract page objects for each range, write to new documents. Add lopdf as an optional dependency behind a 'pdf-ops' feature flag. The conversion pipeline doesn't change — these are new standalone operations."
    },
    {
      "id": "US-096",
      "title": "Add tagged PDF and PDF/UA accessibility support",
      "description": "Tagged PDFs are required for accessibility compliance (PDF/UA, Section 508, WCAG). Krilla (used by Typst) supports tagged PDF generation.\n\nImplement accessibility tagging:\n1. Investigate how typst-pdf generates tagged PDFs — check if there's a tag tree option\n2. If typst-pdf supports it, enable tagged PDF output via configuration\n3. Map document structure to PDF tags:\n   - Headings → `<H1>` to `<H6>`\n   - Paragraphs → `<P>`\n   - Tables → `<Table>`, `<TR>`, `<TD>`, `<TH>`\n   - Images → `<Figure>` with alt text\n   - Lists → `<L>`, `<LI>`\n4. Add `--tagged` CLI flag to enable tagged PDF output\n5. Add `--pdf-ua` CLI flag for PDF/UA compliance (combines PDF/A + tagged PDF)\n6. Add ConvertOptions field: `tagged: bool`, `pdf_ua: bool`\n\nIf typst-pdf doesn't support tagged PDF directly, add the tag tree as a post-processing step on the PDF bytes (using lopdf).",
      "acceptanceCriteria": [
        "Tagged PDF output includes document structure tags (H1-H6, P, Table, Figure)",
        "Headings in source documents map to PDF heading tags",
        "Tables map to Table/TR/TD tags",
        "Images map to Figure tags",
        "--tagged CLI flag enables tagged PDF",
        "--pdf-ua CLI flag enables PDF/UA compliance",
        "ConvertOptions has tagged and pdf_ua fields",
        "Unit test: tagged PDF contains structure tags",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 2,
      "passes": true,
      "notes": "This is a complex story. Start by investigating typst-pdf's tagging capabilities — check the typst-pdf crate docs and source. If Typst 0.14+ supports tagged PDF via krilla, it may be as simple as enabling a flag. If not, consider post-processing with lopdf to add a basic tag tree. For the first iteration, focus on the most impactful tags: headings, paragraphs, and tables. Image alt text can come from the OOXML description attribute."
    },
    {
      "id": "US-097",
      "title": "Auto-generate TypeScript types for WASM API using ts-rs",
      "description": "Inspired by bokuweb/docx-rs, use `ts-rs` to automatically generate TypeScript type definitions from Rust structs used in the WASM API.\n\nImplement:\n1. Add `ts-rs` as an optional dev/build dependency\n2. Derive `TS` on the public API types used in WASM:\n   - ConvertOptions (config.rs)\n   - Format enum (config.rs)\n   - PaperSize enum (config.rs)\n   - ConvertResult (or the WASM equivalent)\n   - ConvertError variants\n3. Generate `.d.ts` type definition files\n4. Add a build script or test that generates types to `crates/office2pdf/bindings/`\n5. Ensure generated types match the wasm-bindgen JavaScript API\n6. Add a CI step that checks type generation is up-to-date\n\nThis improves the WASM developer experience by providing type-safe TypeScript integration.",
      "acceptanceCriteria": [
        "ts-rs derives are added to public WASM API types",
        "TypeScript .d.ts files are generated for ConvertOptions, Format, PaperSize, etc.",
        "Generated types are placed in crates/office2pdf/bindings/",
        "A test verifies type generation succeeds",
        "Generated types match wasm-bindgen function signatures",
        "ts-rs is behind a feature flag (not required for normal builds)",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 3,
      "passes": false,
      "notes": "ts-rs is a well-established crate for Rust-to-TypeScript type generation. Add it as: `ts-rs = { version = '...', optional = true }` with a feature flag like `typescript`. The #[derive(TS)] attribute auto-generates .d.ts files. Place output in a bindings/ directory. This pairs well with the existing wasm-bindgen module in wasm.rs."
    },
    {
      "id": "US-098",
      "title": "Add streaming API for large file processing with bounded memory",
      "description": "Inspired by Apache POI's SXSSF, add a streaming conversion mode for large documents that processes content incrementally without loading the entire document into memory.\n\nApproach:\n1. The primary bottleneck is XLSX — large spreadsheets can consume significant memory\n2. Add a streaming conversion option: `ConvertOptions { streaming: bool }`\n3. In streaming mode for XLSX:\n   - Process rows in chunks (e.g., 1000 rows at a time)\n   - Generate Typst markup incrementally per chunk\n   - Flush each chunk's PDF page(s) before processing the next\n   - This may require multiple Typst compile passes or a streaming Typst API\n4. For DOCX and PPTX, the document is typically small enough that streaming isn't necessary — but add the infrastructure for future use\n5. Add a `--streaming` CLI flag\n6. Memory limit guard: if estimated memory exceeds a threshold (e.g., 500MB), auto-enable streaming mode\n\nThis is architecturally significant — it may require changes to how the IR and Typst codegen work.",
      "acceptanceCriteria": [
        "ConvertOptions has a streaming field",
        "XLSX streaming mode processes rows in configurable chunks",
        "Memory usage for 10,000-row XLSX stays below 200MB in streaming mode",
        "Output is functionally identical between streaming and non-streaming modes",
        "CLI --streaming flag enables streaming mode",
        "Unit test: large XLSX conversion in streaming mode produces valid PDF",
        "Unit test: streaming mode memory usage is bounded",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 4,
      "passes": false,
      "notes": "This is a high-effort story. The current pipeline loads the entire document into IR, then generates all Typst markup at once. Streaming requires rethinking this to process in chunks. For XLSX, the natural chunk boundary is rows — process N rows, generate a page, compile, flush, repeat. umya-spreadsheet may not support streaming reads — if not, at least chunk the IR-to-Typst-to-PDF stage even if the parse stage loads everything. Start with XLSX only and document the approach for future DOCX/PPTX."
    },
    {
      "id": "US-099",
      "title": "Add Prometheus metrics endpoint for production monitoring",
      "description": "When office2pdf runs in server mode (US-094), add Prometheus-compatible metrics for production monitoring.\n\nImplement:\n1. Add a `/metrics` endpoint to the HTTP server that returns Prometheus-format metrics\n2. Track these metrics:\n   - `office2pdf_conversions_total{format, status}` — counter of conversions by format and success/failure\n   - `office2pdf_conversion_duration_seconds{format}` — histogram of conversion durations\n   - `office2pdf_conversion_input_bytes{format}` — histogram of input file sizes\n   - `office2pdf_conversion_output_bytes{format}` — histogram of output PDF sizes\n   - `office2pdf_conversion_pages{format}` — histogram of page counts\n   - `office2pdf_errors_total{format, error_type}` — counter of errors by type\n   - `office2pdf_active_conversions` — gauge of currently in-progress conversions\n3. Use the metrics collected by ConvertMetrics (US-090)\n4. Format output in Prometheus exposition format (text/plain)\n5. Keep implementation simple — no external metrics crate if possible\n\nThis enables dashboards, alerting, and capacity planning for production deployments.",
      "acceptanceCriteria": [
        "GET /metrics returns Prometheus-format metrics",
        "Conversion counter tracks total conversions by format and status",
        "Duration histogram tracks conversion time by format",
        "Active conversions gauge reflects in-progress work",
        "Metrics use standard Prometheus naming conventions",
        "Metrics endpoint works when server mode is running",
        "Integration test: convert a file, then check /metrics shows updated counters",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 5,
      "passes": false,
      "notes": "Prometheus exposition format is simple text: `metric_name{label='value'} 42.0\\n`. Implement a simple in-memory metrics store using AtomicU64 for counters and a Vec<f64> for histograms. No external crate needed for basic Prometheus format. The metrics feature should depend on the server feature flag. Use the ConvertMetrics from US-090 to feed duration/size/page data into the histograms."
    }
  ]
}
