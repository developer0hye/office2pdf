{
  "project": "office2pdf",
  "branchName": "ralph/phase13-bulk-fixture-robustness",
  "description": "Phase 13: Bulk Fixture Robustness - Smoke test all 1000+ third-party fixtures, eliminate panics, improve error recovery",
  "userStories": [
    {
      "id": "US-200",
      "title": "Create bulk conversion smoke test infrastructure",
      "description": "Build an integration test that iterates over ALL fixture files in tests/fixtures/ (including subdirectories libreoffice/ and poi/) and attempts to convert each one to PDF.\n\nImplement:\n1. Create `tests/bulk_conversion.rs` with a test function per format (docx, pptx, xlsx)\n2. Each test discovers all files recursively under `tests/fixtures/{format}/` using glob patterns\n3. For each file, call `office2pdf::convert()` and categorize results:\n   - SUCCESS: conversion completed without error\n   - ERROR: returned a ConvertError (expected for some edge cases)\n   - PANIC: test panics (this is the critical failure mode)\n4. Print a summary table at the end: total files, successes, errors, panics\n5. The test should NOT fail on ConvertError (some files may have unsupported features) — it should only fail if any file causes a panic\n6. Use `std::panic::catch_unwind` to catch panics and continue testing remaining files\n7. Write results to `tests/bulk_conversion_results.txt` for analysis\n\nThis is the foundation for all subsequent robustness work.",
      "acceptanceCriteria": [
        "tests/bulk_conversion.rs exists with per-format test functions",
        "Tests discover all fixture files recursively including libreoffice/ and poi/ subdirectories",
        "Tests use catch_unwind to prevent panics from aborting the full test run",
        "Summary output shows total/success/error/panic counts per format",
        "Tests pass (no panics) OR clearly identify which files cause panics",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 1,
      "passes": true,
      "notes": "Use #[test] functions, not a custom binary. The test should be runnable via `cargo test -p office2pdf --test bulk_conversion -- --nocapture`. Use std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| { ... })) to catch panics. For file discovery, use std::fs::read_dir recursively or the glob crate (already in dev-dependencies). Mark the test with #[ignore] so it doesn't run in normal CI — only when explicitly requested. Print results to stdout AND write to a file."
    },
    {
      "id": "US-201",
      "title": "Fix all DOCX parser panics from bulk fixtures",
      "description": "Run the bulk conversion smoke test on DOCX fixtures and fix ALL panics.\n\nProcess:\n1. Run `cargo test -p office2pdf --test bulk_conversion test_bulk_docx -- --nocapture --ignored` to identify panicking files\n2. For each panicking file, diagnose the root cause (usually unwrap() on None, index out of bounds, or unhandled XML variants)\n3. Fix the parser to handle the edge case gracefully — return ConvertError instead of panicking\n4. Common fixes: replace unwrap() with ok_or/unwrap_or_default, add bounds checks, handle missing XML attributes\n5. Re-run until zero panics on ALL DOCX fixtures (errors are OK, panics are not)\n\nTarget: 0 panics across all DOCX fixtures (libreoffice + poi + existing).",
      "acceptanceCriteria": [
        "Zero panics on all DOCX fixture files (libreoffice/, poi/, and root)",
        "All unwrap()/expect() calls in DOCX parser that could trigger on real data are replaced with error handling",
        "Bulk DOCX test reports 0 panics in summary",
        "No regressions in existing unit/integration tests",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 2,
      "passes": false,
      "notes": "Focus on panics ONLY, not on conversion quality. A file that returns ConvertError::Parse is fine — a file that crashes with 'index out of bounds' is not. Common panic sources in DOCX parsing: serde_json path navigation (.get().unwrap()), numbering definition lookups, image relationship resolution, header/footer parsing. Use .unwrap_or_default(), .ok_or(), or early return with ? to handle missing data."
    },
    {
      "id": "US-202",
      "title": "Fix all PPTX parser panics from bulk fixtures",
      "description": "Run the bulk conversion smoke test on PPTX fixtures and fix ALL panics.\n\nProcess:\n1. Run `cargo test -p office2pdf --test bulk_conversion test_bulk_pptx -- --nocapture --ignored` to identify panicking files\n2. For each panicking file, diagnose root cause\n3. Fix the PPTX parser to handle edge cases gracefully\n4. Re-run until zero panics on ALL PPTX fixtures\n\nTarget: 0 panics across all PPTX fixtures (libreoffice + poi + existing).",
      "acceptanceCriteria": [
        "Zero panics on all PPTX fixture files (libreoffice/, poi/, and root)",
        "All unwrap()/expect() calls in PPTX parser that could trigger on real data are replaced with error handling",
        "Bulk PPTX test reports 0 panics in summary",
        "No regressions in existing unit/integration tests",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 3,
      "passes": false,
      "notes": "Common PPTX panic sources: XML attribute parsing (.attribute().unwrap()), missing slide relationships, theme color resolution, shape geometry parsing, SmartArt/chart XML navigation. The PPTX parser uses quick-xml directly so look for unchecked .unwrap() calls on attribute reads and element iteration."
    },
    {
      "id": "US-203",
      "title": "Fix all XLSX parser panics from bulk fixtures",
      "description": "Run the bulk conversion smoke test on XLSX fixtures and fix ALL panics.\n\nProcess:\n1. Run `cargo test -p office2pdf --test bulk_conversion test_bulk_xlsx -- --nocapture --ignored` to identify panicking files\n2. For each panicking file, diagnose root cause\n3. Fix the XLSX parser to handle edge cases gracefully\n4. Re-run until zero panics on ALL XLSX fixtures\n\nTarget: 0 panics across all XLSX fixtures (libreoffice + poi + existing).",
      "acceptanceCriteria": [
        "Zero panics on all XLSX fixture files (libreoffice/, poi/, and root)",
        "All unwrap()/expect() calls in XLSX parser that could trigger on real data are replaced with error handling",
        "Bulk XLSX test reports 0 panics in summary",
        "No regressions in existing unit/integration tests",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 4,
      "passes": false,
      "notes": "Common XLSX panic sources: umya-spreadsheet API calls returning unexpected None, cell type mismatches, shared string index out of bounds, date/number format parsing, conditional formatting evaluation. The XLSX parser wraps umya-spreadsheet so most panics will be in the boundary code between umya and our IR."
    },
    {
      "id": "US-204",
      "title": "Fix all Typst codegen and PDF render panics",
      "description": "After fixing parser panics, some files may still panic during Typst codegen or PDF rendering. Fix these too.\n\nProcess:\n1. Re-run full bulk conversion tests to find remaining panics (should only be in codegen/render now)\n2. Common codegen panics: unhandled IR variants, string formatting edge cases, image asset resolution\n3. Common render panics: Typst compilation errors that aren't caught, font issues\n4. Fix all remaining panics across ALL formats\n\nTarget: 0 panics on ANY fixture file in the entire tests/fixtures/ tree.",
      "acceptanceCriteria": [
        "Zero panics on ANY fixture file across all three formats",
        "Typst codegen handles all IR variants without panicking",
        "PDF render catches Typst compilation errors and returns ConvertError",
        "Bulk conversion summary shows 0 panics for all formats combined",
        "No regressions in existing unit/integration tests",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 5,
      "passes": false,
      "notes": "This is the final sweep. By this point, parser panics should be fixed. Remaining panics are likely in typst_gen.rs (unhandled match arms, string building) or pdf.rs (Typst world trait implementation, font loading). The goal is ZERO panics on any input — malformed files should return errors, never crash."
    },
    {
      "id": "US-205",
      "title": "Achieve 70%+ overall conversion success rate",
      "description": "After eliminating panics, improve the conversion success rate by fixing the most common ConvertError patterns.\n\nProcess:\n1. Run bulk tests and analyze the error distribution — group errors by type/message\n2. Identify the top 3-5 most frequent error patterns\n3. Fix each pattern (usually missing feature support or parser limitations)\n4. Target: at least 70% of all fixtures convert successfully to PDF\n\nThis is about improving coverage, not perfection. Focus on the errors that affect the most files.",
      "acceptanceCriteria": [
        "Bulk conversion success rate is 70% or higher across all formats combined",
        "Top 3 most common error patterns are identified and addressed",
        "Error messages are descriptive enough to diagnose remaining failures",
        "No regressions in existing unit/integration tests",
        "cargo test --workspace passes",
        "cargo fmt --all -- --check passes",
        "cargo clippy --workspace -- -D warnings passes"
      ],
      "priority": 6,
      "passes": false,
      "notes": "Common error patterns that block many files: missing image relationships (broken refs), unsupported XML namespaces, Typst compilation failures from invalid markup, password-protected files. For password-protected or intentionally broken files, classify them as 'expected failures' and exclude from the success rate calculation. The 70% target is deliberately achievable — it means fixing the most impactful issues without getting stuck on obscure edge cases."
    }
  ]
}
